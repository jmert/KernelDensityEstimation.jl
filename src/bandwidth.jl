import LinearAlgebra: Symmetric, cholesky, cholesky!, isposdef

# convenient wrapper for univariate inputs
function bandwidth(estim::AbstractBandwidthEstimator,
                   data::AbstractVector, bounds::Tuple{Any,Any,Boundary.T},
                   weights::Union{Nothing,<:AbstractVector} = nothing)
    return bandwidth(estim, (data,), (bounds,), weights)
end


# Get the effective sample size and (co)variance simultaneously
#
#   - Calculate variance via Welford's algorithm:
#
#     https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford%27s_online_algorithm
#
#   - Calculate the effective sample size, based on weights and the bounds, using the
#     Kish effective sample size definition:
#
#         n_eff = sum(weights)^2 / sum(weights .^ 2)
#
#     https://search.r-project.org/CRAN/refmans/svyweight/html/eff_n.html
#     https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Reliability_weights
function _neff_covar(coords::Tuple{Vararg{AbstractVector,N}},
                     lo::Tuple{Vararg{Any,N}},
                     hi::Tuple{Vararg{Any,N}},
                     weights::Union{Nothing,<:AbstractVector}) where {N}
    T = promote_type(map(_unitlessâˆ˜eltype, coords)...)
    wsum = wsqr = isnothing(weights) ? zero(T) : zero(eltype(weights))

    x = zeros(T, N)
    Î¼ = zeros(T, N)
    Î¼â‚‹â‚ = zeros(T, N)
    Î£ = zeros(T, N, N)
    I = isnothing(weights) ? eachindex(coords...) : eachindex(weights, coords...)
    for ii in I
        # @. x = coords[ii] * _invunit(typeof(coords[ii]))
        # !all(@. lo â‰¤ x â‰¤ hi) && continue
        indomain = true
        for jj in 1:N
            v = coords[jj][ii]
            x[jj] = v * oneunit(_invunit(typeof(v)))
            indomain &= lo[jj] â‰¤ v â‰¤ hi[jj]
        end
        !indomain && continue

        w = isnothing(weights) ? one(wsum) : weights[ii]
        wsum += w
        wsqr += w^2
        Ï‰ = w / wsum
        Ï‰Ì„ = one(Ï‰) - Ï‰

        # @. Î¼â‚‹â‚ = Î¼
        # @. Î¼ = Ï‰Ì„ * Î¼â‚‹â‚ + Ï‰ * x
        for jj in 1:N
            Î¼â‚‹â‚[jj] = Î¼[jj]
            Î¼[jj] = Ï‰Ì„ * Î¼[jj] + Ï‰ * x[jj]
        end
        # @. Î£ = Ï‰Ì„ * Î£ + Ï‰ * (x - Î¼) * (x - Î¼â‚‹â‚)'
        for jj in 1:N
            yy = x[jj] - Î¼â‚‹â‚[jj]
            for kk in 1:N
                Î£[kk,jj] = Ï‰Ì„ * Î£[kk, jj] + Ï‰ * (x[kk] - Î¼[kk]) * yy
            end
        end
    end
    neff = wsum^2 / wsqr
    return neff, Î£
end

# specialize for 1D case where the variance is scalar, so allocating arrays can be avoided
function _neff_covar(coords::Tuple{AbstractVector},
                     lo::Tuple{Any},
                     hi::Tuple{Any},
                     weights::Union{Nothing,<:AbstractVector})
    T = promote_type(map(_unitlessâˆ˜eltype, coords)...)
    wsum = wsqr = isnothing(weights) ? zero(T) : zero(eltype(weights))

    x = zero(T)
    Î¼ = zero(T)
    Î¼â‚‹â‚ = zero(T)
    Î£ = zero(T)
    I = isnothing(weights) ? eachindex(coords...) : eachindex(weights, coords...)
    for ii in I
        v = coords[1][ii]
        lo[1] â‰¤ v â‰¤ hi[1] || continue
        x = v * oneunit(_invunit(typeof(v)))

        w = isnothing(weights) ? one(wsum) : weights[ii]
        wsum += w
        wsqr += w^2
        Ï‰ = w / wsum
        Ï‰Ì„ = one(Ï‰) - Ï‰

        Î¼â‚‹â‚ = Î¼
        Î¼ = Ï‰Ì„ * Î¼ + Ï‰ * x
        Î£ = Ï‰Ì„ * Î£ + Ï‰ * (x - Î¼) * (x - Î¼â‚‹â‚)
    end
    neff = wsum^2 / wsqr
    return neff, Î£
end


"""
    SilvermanBandwidth <: AbstractBandwidthEstimator

Estimates the necessary bandwidth of data at ``d``-dimensional coordinates
``(ð’—_1, ð’—_2, â€¦, ð’—_d)`` with weights ``ð’˜`` using Silverman's Rule for a Gaussian smoothing
kernel.

For the univariate (``d = 1``) case:
```math
    h = \\left(\\frac{4}{3n_\\mathrm{eff}}\\right)^{1/5} ÏƒÌ‚
```
where ``n_\\mathrm{eff}`` is the effective number of degrees of freedom of the data and
``ÏƒÌ‚^2`` is its sample variance.

In the multivariate case (``d â‰¥ 2``):
```math
    ð’‰ = \\left(\\frac{4}{(2 + d)n_\\mathrm{eff}}\\right)^{1/(4 + d)} \\sqrt{ðœ®Ì‚}
```
where ``\\sqrt{ðœ®Ì‚}`` is a Cholesky decomposition of the weighted sample covariance.

See also [`ISJBandwidth`](@ref)

# Extended help

The sample (co)variance and effective number of degrees of freedom are calculated using
weighted statistics, where the latter is defined to be Kish's effective sample size
``n_\\mathrm{eff} = (\\sum_i ð’˜_i)^2 / \\sum_i ð’˜_i^2``.
For uniform weights, this reduces to the length of the vector(s) ``ð’—_j``.

## References
- [Hansen2009](@citet)
"""
struct SilvermanBandwidth <: AbstractBandwidthEstimator end

function bandwidth(::SilvermanBandwidth,
                   data::Tuple{Vararg{AbstractVector,N}},
                   bounds::Tuple{Vararg{Tuple{Any,Any,Boundary.T},N}},
                   weights::Union{Nothing,<:AbstractVector} = nothing
                   ) where {N}
    T = promote_type(map(_unitlessâˆ˜eltype, data)...)
    lo = map(b -> b[1], bounds)
    hi = map(b -> b[2], bounds)
    neff, Î£ = _neff_covar(data, lo, hi, weights)
    # From Hansen (2009) â€” https://users.ssc.wisc.edu/~bhansen/718/NonParametrics1.pdf
    # for a Gaussian kernel:
    # - Table 1:
    #   - R(k) = 1 / 2âˆšÏ€
    #   - Îºâ‚‚(k) = 1
    #   - Î½ = 2
    # - Section 2.11 (for uncorrelated dimensions):
    #   - bw_j = ÏƒÌ‚_j Câ‚‚(k,d) n^(-1/(4+d))
    #     Câ‚‚(k,d) = (4/(2 + d))^(1/(4+d))
    #   - bw_j = ÏƒÌ‚_j * (4/(2 + d)n)^(1/(4+d))
    bw_scale = (oftype(one(T), (4one(T) / (2 + N))) / neff)^(one(T) / (4 + N))
    # where the bandwidth scaling factor is derived for uncorrelated dimensions.
    # Because a non-diagonal covariance matrix can be diagonalized via eigenvalue
    # decomposition, the scaling factor still applies:
    cov_scale = bw_scale ^ 2
    # Î£ *= cov_scale
    for jj in 1:N
        for kk in 1:N
            Î£[kk, jj] *= cov_scale
        end
    end
    C = cholesky(Symmetric(Î£, :L), check = false)
    isposdef(C) && return C

    # If the cholesky factorization failed, its presumably due to a degenerate case like
    # zero variance in one of the directions or perfect correlation between two dimensions.
    # Regularize the problem by adding a small perterbation to the diagonal of the
    # covariance matrix, and then try again.

    # Ïµ = eps(maximum(Î£[diagind(Î£)]))
    Ïµ = floatmin(T)
    for jj in 1:N
        Ïµ = max(Ïµ, Î£[jj, jj])
    end
    Ïµ = eps(Ïµ)

    # Î£ .+= Ïµ * I
    for jj in 1:N
        Î£[jj, jj] += Ïµ
    end
    return cholesky!(Symmetric(Î£, :L))
end

# specialize for 1D case where the variance is scalar, so allocating arrays can be avoided
function bandwidth(::SilvermanBandwidth,
                   data::Tuple{AbstractVector},
                   bounds::Tuple{Tuple{Any,Any,Boundary.T}},
                   weights::Union{Nothing,<:AbstractVector} = nothing
                   )
    T = promote_type(map(_unitlessâˆ˜eltype, data)...)
    lo = (bounds[1][1],)
    hi = (bounds[1][2],)
    neff, Î£ = _neff_covar(data, lo, hi, weights)
    # From Hansen (2009) â€” https://users.ssc.wisc.edu/~bhansen/718/NonParametrics1.pdf
    # for a Gaussian kernel:
    # - Table 1:
    #   - R(k) = 1 / 2âˆšÏ€
    #   - Îºâ‚‚(k) = 1
    #   - Î½ = 2
    # - Section 2.11 (for uncorrelated dimensions):
    #   - bw_j = ÏƒÌ‚_j Câ‚‚(k,d) n^(-1/(4+d))
    #     Câ‚‚(k,d) = (4/(2 + d))^(1/(4+d))
    #   - bw_j = ÏƒÌ‚_j * (4/(2 + d)n)^(1/(4+d))
    bw_scale = (oftype(one(T), (4one(T) / 3)) / neff)^(one(T) / 5)
    return iszero(Î£) ? sqrt(eps(bw_scale^2)) : sqrt(Î£) * bw_scale
end

module ISJ
    # An implementation of Brent's method, translated from the algorithm described in
    #   https://en.wikipedia.org/wiki/Brent%27s_method
    #
    # The reference description provides no guidance on the stopping criteria, so we choose to
    # use both relative and absolute tolerances (similar to `isapprox()`).
    function brent(f, a::T, b::T; abstol = nothing, reltol = nothing) where {T}
        Î´ = isnothing(abstol) ? eps(abs(b - a)) : T(abstol)
        Îµ = isnothing(reltol) ? eps(abs(b - a)) : T(reltol)
        fa = f(a)
        fb = f(b)
        if fa * fb â‰¥ zero(T)
            # not a bracketing interval
            return oftype(a, NaN)
        end
        if abs(fa) < abs(fb)
            b, a = a, b
            fb, fa = fa, fb
        end

        c, fc = a, fa
        d = s = b
        mflag = true

        while true
            Î” = abs(b - a)
            if iszero(fb) || Î” <= Î´ || Î” <= abs(b) * Îµ
                # converged
                return b
            end

            if fa != fc && fb != fc
                # inverse quadratic interpolation
                s = ( a * fb * fc / ((fa - fb) * (fa - fc))
                    + b * fa * fc / ((fb - fa) * (fb - fc))
                    + c * fa * fb / ((fc - fa) * (fc - fb)))
            else
                # secant
                s = b - fb * (b - a) / (fb - fa)
            end

            u, v = (3a + b) / 4, b
            if u > v
                u, v = v, u
            end
            tol = max(Î´, max(abs(b), abs(c), abs(d)) * Îµ)

            cond1 = !(u < s < v)
            cond23 = abs(s - b) â‰¥ abs(mflag ? b - c : c - d) / 2
            cond45 = abs(mflag ? b - c : c - d) < tol
            if cond1 || cond23 || cond45
                # bisection
                s = (a + b) / 2
                mflag = true
            else
                mflag = false
            end
            fs = f(s)
            if iszero(fs)
                return s
            end

            c, fc, d = b, fb, c
            if sign(fa) * sign(fs) < zero(T)
                b, fb = s, fs
            else
                a, fa = s, fs
            end

            if abs(fa) < abs(fb)
                b, a = a, b
                fb, fa = fa, fb
            end
        end
    end

    # Calculates norm of the the j-th derivative of the convolved density function, e.g.
    #
    #   ||âˆ‚Ê²/âˆ‚xÊ²[ f(x) * K_h(x) ]||Â²
    #
    # but in an efficient way which makes use of knowing K_h(x) is a Gaussian with
    # standard deviation h and using the dicrete cosine transform of the distribution
    # since convolution and derivatives are efficient in Fourier space.
    function âˆ‚Ê²(fÌ‚::Vector{T}, h::T, j::Integer) where T <: Real
        N = length(fÌ‚)
        expfac = -(2T(Ï€) * h)^2

        norm = zero(T)
        for n in 1:(N - 1)
            fÌ‚â‚™Â² = abs2(fÌ‚[n + 1])
            kâ‚™ = T(n) / 2N
            norm += fÌ‚â‚™Â² * kâ‚™^(2j) * exp(expfac * kâ‚™^2)
        end
        if j == 0
            norm += abs2(fÌ‚[1]) / 2
        end
        norm *= (2T(Ï€))^(2j) / 2N
        return norm
    end

    # Calculates the Î³ function, defined in Botev et al as the right-hand side of Eqn. 29
    function Î³(neff::T, fÌ‚::Vector{T}, j::Int, h::T) where {T<:Real}
        NÂ² = âˆ‚Ê²(fÌ‚, h, j + 1)
        fac1 = (T(1) + T(2) ^ -T(j + 0.5)) / 3
        fac2 = mapreduce(T, *, 1:2:(2j-1)) / (sqrt(T(Ï€) / 2) * neff * NÂ²)
        return (fac1 * fac2) ^ (T(1) / (2j + 3))
    end

    # Calculates the iteratively-defined Î³Ë¡ function, defined in Botev et al, between
    # Eqns. 29 and 30.
    function Î³Ë¡(l::Int, neff::T, fÌ‚::Vector{T}, h::T) where {T<:Real}
        for j in l:-1:1
            h = Î³(neff, fÌ‚, j, h)
        end
        return h
    end

    # Express the fixed-point equation (Botev et al Eqn. 30) as an expression where the
    # root is the desired bandwidth.
    function estimate(l::Int, neff::T, fÌ‚::Vector{T}, hâ‚€::T) where {T<:Real}
        Î¾ = ((6sqrt(T(2)) - 3) / 7) ^ (one(T) / 5)
        return brent(eps(hâ‚€), 8hâ‚€) do h
            return h - Î¾ * Î³Ë¡(l, neff, fÌ‚, h)
        end
    end
end

"""
    ISJBandwidth <: AbstractBandwidthEstimator

Estimates the necessary bandwidth of a vector of data ``v`` using the Improved
Sheather-Jones (ISJ) plug-in estimator of [Botev2010](@citet).

This estimator is more capable of choosing an appropriate bandwidth for bimodal (and other
highly non-Gaussian) distributions, but comes at the expense of greater computation time
and no guarantee that the estimator converges when given very few data points.

See also [`SilvermanBandwidth`](@ref)

## Fields
- `binning::`[`AbstractBinningKDE`](@ref): The binning type to apply to a data vector as the
  first step of bandwidth estimation.
  Defaults to [`HistogramBinning()`](@ref).

- `bwratio::Int`: The relative resolution of the binned data used by the ISJ plug-in
  estimator â€” there are `bwratio` bins per interval of size ``hâ‚€``, where the intial
  rough initial bandwidth estimate is given by the [`SilvermanBandwidth`](@ref) estimator.
  Defaults to 2.

- `niter::Int`: The number of iterations to perform in the plug-in estimator.
  Defaults to 7, in accordance with Botev et. al. who state that higher orders show little
  benefit.

- `fallback::Bool`: Whether to fallback to the [`SilvermanBandwidth`](@ref) if the ISJ
  estimator fails to converge. If `false`, an exception is thrown instead.

## References
- [Botev2010](@citet)
"""
Base.@kwdef struct ISJBandwidth{B<:AbstractBinningKDE,R<:Real} <: AbstractBandwidthEstimator
    binning::B = HistogramBinning()
    bwratio::R = 2
    niter::Int = 7
    fallback::Bool = true
end

function bandwidth(isj::ISJBandwidth{<:Any},
                   data::Tuple{AbstractVector{T}},
                   bounds::Tuple{Tuple{T, T, Boundary.T}},
                   weights::Union{Nothing, <:AbstractVector} = nothing
                   ) where {T}
    # The Silverman bandwidth estimator should be sufficient to obtain a fine-enough
    # binning that the ISJ algorithm can iterate.
    # We need a histogram, so just reuse the binning base case of the estimator pipeline
    # to provide what we need.
    (x, f), info = estimate(isj.binning, data[1], weights; bounds, isj.bwratio,
                            bandwidth = SilvermanBandwidth())

    bandwidth = info.bandwidth[1]
    neff = info.neffective
    Î”x = (tmp = step(x); tmp / oneunit(tmp))
    # The core of the ISJ algorithm works in a normalized unit system where Î”x = 1.
    # Two things of note:
    #
    #   1. We initialize the fixed-point algorithm with the Silverman bandwidth, but
    #      scaled correctly for the change in axis. Then afterwards, the ISJ bandwidth
    #      will need to be scaled back to the original axis, e.g. h â†’ Î”x Ã— h
    hâ‚€ = bandwidth / Î”x
    #   2. Via the Fourier scaling theorem, f(x / Î”x) â‡” Î”x Ã— fÌ‚(k), we must scale the DCT
    #      by the grid step size.
    fÌ‚ = similar(f, _unitless(T))
    @simd for I in eachindex(f)
        @inbounds fÌ‚[I] = f[I] * oneunit(T)
    end
    FFTW.r2r!(fÌ‚, FFTW.REDFT10)
    rmul!(fÌ‚, Î”x)

    # Now we simply solve for the fixed-point solution:
    h = Î”x * ISJ.estimate(isj.niter, neff, fÌ‚, hâ‚€)

    # Check that the fixed-point solver converged to a positive value
    if isnan(h) || h < zero(h)
        if isj.fallback
            h = bandwidth  # fallback to the Silverman estimate
        else
            throw(ErrorException("ISJ estimator failed to converge. More data is needed."))
        end
    end
    return h
end
