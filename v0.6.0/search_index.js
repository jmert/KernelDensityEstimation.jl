var documenterSearchIndex = {"docs":
[{"location":"references/#References","page":"References","title":"References","text":"","category":"section"},{"location":"references/","page":"References","title":"References","text":"M. Jones and P. Foster. A simple nonnegative boundary correction method for kernel density                  estimation. Statistica Sinica, 1005–1013 (1996).\n\n\n\nA. Lewis. GetDist: a Python package for analysing Monte Carlo samples, arXiv e-prints (2019), arXiv:1910.13970.\n\n\n\nB. Hansen. Lecture Notes on Nonparametrics (2009).\n\n\n\nZ. Botev, J. Grotowski and D. Kroese. Kernel density estimation via diffusion. The Annals of Statistics 38 (2010), arXiv:1011.2602.\n\n\n\n","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"CurrentModule = KernelDensityEstimation","category":"page"},{"location":"api/","page":"API","title":"API","text":"Pages = [\"api.md\"]\nDepth = 2:2","category":"page"},{"location":"api/#User-Interface","page":"API","title":"User Interface","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"kde\nUnivariateKDE\nBoundary","category":"page"},{"location":"api/#KernelDensityEstimation.kde","page":"API","title":"KernelDensityEstimation.kde","text":"estim = kde(v;\n            method = MultiplicativeBiasKDE(),\n            lo = nothing, hi = nothing, boundary = :open, bounds = nothing,\n            bandwidth = ISJBandwidth(), bwratio = 8 nbins = nothing)\n\nCalculate a discrete kernel density estimate (KDE) f(x) from samples v.\n\nThe default method of density estimation uses the MultiplicativeBiasKDE pipeline, which includes corrections for boundary effects and peak broadening which should be an acceptable default in many cases, but a different AbstractKDEMethod can be chosen if necessary.\n\nThe interval of the density estimate can be controlled by either the set of lo, hi, and boundary keywords or the bounds keyword, where the former are conveniences for setting bounds = (lo, hi, boundary). The minimum and maximum of v are used if lo and/or hi are nothing, respectively. (See also bounds.)\n\nThe KDE is constructed by first histogramming the input v into nbins many bins with outermost bin edges spanning lo to hi. The span of the histogram may be expanded outward based on boundary condition, dictating whether the boundaries are open or closed. The bwratio parameter is used to calculate nbins when it is not given and corresponds (approximately) to the ratio of the bandwidth to the width of each histogram bin.\n\nAcceptable values of boundary are:\n\n:open or Open\n:closed or Closed\n:closedleft, :openright, ClosedLeft, or OpenRight\n:closedright, :openleft, ClosedRight, or OpenLeft\n\nThe histogram is then convolved with a Gaussian distribution with standard deviation bandwidth. The default bandwidth estimator is the Improved Sheather-Jones (ISJBandwidth) if no explicit bandwidth is given.\n\n\n\n\n\n","category":"function"},{"location":"api/#KernelDensityEstimation.UnivariateKDE","page":"API","title":"KernelDensityEstimation.UnivariateKDE","text":"UnivariateKDE{T,U,R<:AbstractRange{T},V<:AbstractVector{U}} <: AbstractKDE{T}\n\nFields\n\nx::R: The locations (bin centers) of the corresponding density estimate values.\nf::V: The density estimate values.\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.Boundary","page":"API","title":"KernelDensityEstimation.Boundary","text":"@enum T Closed Open ClosedLeft ClosedRight\nconst OpenLeft = ClosedRight\nconst OpenRight = ClosedLeft\n\nEnumeration to describe the desired boundary conditions of the domain of the kernel density estimate K. For some given data d  a b, the boundary conditions have the following impact:\n\nClosed: The domain K  a b is used directly as the bounds of the binning.\nOpen: The desired domain K  (- +) is effectively achieved by widening the bounds of the data by the size of the finite convolution kernel. Specifically, the binning is defined over the range a - 8σ b + 8σ where σ is the bandwidth of the Gaussian convolution kernel.\nClosedLeft: The left half-closed interval K  a +) is used as the bounds for binning by adjusting the upper limit to the range a b + 8σ. The equivalent alias OpenRight may also be used.\nClosedRight: The right half-closed interval K  (- b is used as the bounds for binning by adjusting the lower limit to the range a - 8σ b. The equivalent alias OpenLeft may also be used.\n\n\n\n\n\n","category":"module"},{"location":"api/#Advanced-User-Interface","page":"API","title":"Advanced User Interface","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"init","category":"page"},{"location":"api/#KernelDensityEstimation.init","page":"API","title":"KernelDensityEstimation.init","text":"data, details = init(method::K, data::AbstractVector{T};\n                     lo::Union{Nothing,<:Number} = nothing,\n                     hi::Union{Nothing,<:Number} = nothing,\n                     boundary::Union{Symbol,Boundary.T} = :open,\n                     bounds = nothing,\n                     bandwidth::Union{<:Number,<:AbstractBandwidthEstimator} = ISJBandwidth(),\n                     bwratio::Real = 1,\n                     nbins::Union{Nothing,<:Integer} = nothing,\n                     kwargs...) where {K<:AbstractKDEMethod, T}\n\n\n\n\n\n","category":"function"},{"location":"api/#Binning-Methods","page":"API","title":"Binning Methods","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AbstractBinningKDE\nHistogramBinning\nLinearBinning","category":"page"},{"location":"api/#KernelDensityEstimation.AbstractBinningKDE","page":"API","title":"KernelDensityEstimation.AbstractBinningKDE","text":"AbstractBinningKDE <: AbstractKDEMethod\n\nThe abstract supertype of data binning methods which are the first step in the density estimation process. The two supported binning methods are HistogramBinning and LinearBinning.\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.HistogramBinning","page":"API","title":"KernelDensityEstimation.HistogramBinning","text":"struct HistogramBinning <: AbstractBinningKDE end\n\nBase case which generates a density estimate by histogramming the data.\n\nSee also LinearBinning\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.LinearBinning","page":"API","title":"KernelDensityEstimation.LinearBinning","text":"struct LinearBinning <: AbstractBinningKDE end\n\nBase case which generates a density estimate by linear binning of the data.\n\nSee also HistogramBinning\n\n\n\n\n\n","category":"type"},{"location":"api/#Density-Estimation-Methods","page":"API","title":"Density Estimation Methods","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"BasicKDE\nLinearBoundaryKDE\nMultiplicativeBiasKDE","category":"page"},{"location":"api/#KernelDensityEstimation.BasicKDE","page":"API","title":"KernelDensityEstimation.BasicKDE","text":"BasicKDE{M<:AbstractBinningKDE} <: AbstractKDEMethod\n\nA baseline density estimation technique which convolves a binned dataset with a Gaussian kernel truncated at its 4σ bounds.\n\nFields and Constructor Keywords\n\nbinning::AbstractBinningKDE: The binning type to apply to a data vector as the first step of density estimation. Defaults to HistogramBinning().\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.LinearBoundaryKDE","page":"API","title":"KernelDensityEstimation.LinearBoundaryKDE","text":"LinearBoundaryKDE{M<:AbstractBinningKDE} <: AbstractKDEMethod\n\nA method of KDE which applies the linear boundary correction of Jones and Foster [1] as described in Lewis [2] after BasicKDE density estimation. This correction primarily impacts the KDE near a closed boundary (see Boundary) and has the effect of improving any non-zero gradient at the boundary (when compared to normalization corrections which tend to leave the boundary too flat).\n\nFields and Constructor Keywords\n\nbinning::AbstractBinningKDE: The binning type to apply to a data vector as the first step of density estimation. Defaults to HistogramBinning().\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.MultiplicativeBiasKDE","page":"API","title":"KernelDensityEstimation.MultiplicativeBiasKDE","text":"MulitplicativeBiasKDE{B<:AbstractBinningKDE,M<:AbstractKDEMethod} <: AbstractKDEMethod\n\nA method of KDE which applies the multiplicative bias correction described in Lewis [2]. This correction is designed to reduce the broadening of peaks inherent to kernel convolution by using a pilot KDE to flatten the distribution and run a second iteration of density estimation (since a perfectly uniform distribution cannot be broadened further).\n\nFields and Constructor Keywords\n\nbinning::AbstractBinningKDE: The binning type to apply to a data vector as the first step of density estimation. Defaults to HistogramBinning().\nmethod::AbstractKDEMethod: The KDE method to use for the pilot and iterative density estimation. Defaults to LinearBoundaryKDE().\n\nNote that if the given method has a configurable binning type, it is ignored in favor of the explicit binning chosen.\n\n\n\n\n\n","category":"type"},{"location":"api/#Bandwidth-Estimators","page":"API","title":"Bandwidth Estimators","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AbstractBandwidthEstimator\nSilvermanBandwidth\nISJBandwidth\nbandwidth","category":"page"},{"location":"api/#KernelDensityEstimation.AbstractBandwidthEstimator","page":"API","title":"KernelDensityEstimation.AbstractBandwidthEstimator","text":"AbstractBandwidthEstimator\n\nAbstract supertype of kernel bandwidth estimation techniques.\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.SilvermanBandwidth","page":"API","title":"KernelDensityEstimation.SilvermanBandwidth","text":"SilvermanBandwidth <: AbstractBandwidthEstimator\n\nEstimates the necessary bandwidth of a vector of data v using Silverman's Rule for a Gaussian smoothing kernel:\n\n    h = left(frac43nright)^15 σ\n\nwhere n is the length of v and σ is its sample variance.\n\nSee also ISJBandwidth\n\nReferences\n\nHansen [3]\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.ISJBandwidth","page":"API","title":"KernelDensityEstimation.ISJBandwidth","text":"ISJBandwidth <: AbstractBandwidthEstimator\n\nEstimates the necessary bandwidth of a vector of data v using the Improved Sheather-Jones (ISJ) plug-in estimator of Botev et al. [4].\n\nThis estimator is more capable of choosing an appropriate bandwidth for bimodal (and other highly non-Gaussian) distributions, but comes at the expense of greater computation time and no guarantee that the estimator converges when given very few data points.\n\nSee also SilvermanBandwidth\n\nFields\n\nbinning::AbstractBinningKDE: The binning type to apply to a data vector as the first step of bandwidth estimation. Defaults to HistogramBinning().\nbwratio::Int: The relative resolution of the binned data used by the ISJ plug-in estimator — there are bwratio bins per interval of size h₀, where the intial rough initial bandwidth estimate is given by the SilvermanBandwidth estimator. Defaults to 2.\nniter::Int: The number of iterations to perform in the plug-in estimator. Defaults to 7, in accordance with Botev et. al. who state that higher orders show little benefit.\nfallback::Bool: Whether to fallback to the SilvermanBandwidth if the ISJ estimator fails to converge. If false, an exception is thrown instead.\n\nReferences\n\nBotev et al. [4]\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.bandwidth","page":"API","title":"KernelDensityEstimation.bandwidth","text":"h = bandwidth(estimator::AbstractBandwidthEstimator, data::AbstractVector{T},\n              lo::T, hi::T, boundary::Boundary.T) where {T}\n\nDetermine the appropriate bandwidth h of the data set data using chosen estimator algorithm. The bandwidth is provided the range (lo through hi) and boundary style (boundary) of the request KDE method for use in filtering and/or correctly interpreting the data, if necessary.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/#Interfaces","page":"API","title":"Interfaces","text":"","category":"section"},{"location":"api/#Density-Estimation-Methods-2","page":"API","title":"Density Estimation Methods","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"AbstractKDE\nAbstractKDEInfo\nUnivariateKDEInfo\nAbstractKDEMethod\nboundary\nbounds\nestimate\nestimator_order","category":"page"},{"location":"api/#KernelDensityEstimation.AbstractKDE","page":"API","title":"KernelDensityEstimation.AbstractKDE","text":"AbstractKDE{T}\n\nAbstract supertype of kernel density estimates.\n\nSee also UnivariateKDE\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.AbstractKDEInfo","page":"API","title":"KernelDensityEstimation.AbstractKDEInfo","text":"AbstractKDEInfo{T}\n\nAbstract supertype of auxiliary information used during kernel density estimation.\n\nSee also UnivariateKDEInfo\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.UnivariateKDEInfo","page":"API","title":"KernelDensityEstimation.UnivariateKDEInfo","text":"UnivariateKDEInfo{T} <: AbstractKDEInfo{T}\n\nInformation about the density estimation process, providing insight into both the entrypoint parameters and some internal state variables.\n\nExtended help\n\nFields\n\nmethod::AbstractKDEMethod: The estimation method used to generate the KDE.\nbounds::Any: The bounds specification of the estimate as passed to init(), prior to making it concrete via calling bounds(). Defaults to nothing.\ninterval::Tuple{T,T}: The concrete interval of the density estimate after calling bounds() with the value of the .bounds field but before adding requisite padding for open boundary conditions. Defaults to (zero(T), zero(T)).\nboundary::Boundary.T: The concrete boundary condition assumed in the density estimate after calling boundary() with the value of the .bounds field. Defaults to Open.\nnpoints::Int: The number of values in the original data vector. Defaults to -1.\nbandwidth_alg::Union{Nothing,AbstractBandwidthEstimator}: Algorithm used to estimate an appropriate bandwidth, if a concrete value was not provided to the estimator, otherwise nothing. Defaults to nothing.\nbandwidth::T: The bandwidth of the convolution kernel. Defaults to zero(T).\nbwratio::T: The ratio between the bandwidth and the width of a histogram bin, used only when the number of bins .nbins is not explicitly provided. Defaults to one(T).\nlo::T: The lower edge of the first bin in the density estimate, after possibly adjusting for an open boundary condition compared to the .interval field. Defaults to zero(T).\nhi::T: The upper edge of the last bin in the density estimate, after possibly adjusting for an open boundary condition compared to the .interval field. Defaults to zero(T).\nnbins::Int: The number of bins used in the histogram at the beinning of the density estimatation. Defaults to -1.\nkernel::Union{Nothing,UnivariateKDE{T}}: The convolution kernel used to process the density estimate. Defaults to nothing.\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.AbstractKDEMethod","page":"API","title":"KernelDensityEstimation.AbstractKDEMethod","text":"AbstractKDEMethod\n\nThe abstract supertype of all kernel density estimation methods, including the data binning process (see AbstractBinningKDE) and subsequent density estimation techniques (such as BasicKDE).\n\n\n\n\n\n","category":"type"},{"location":"api/#KernelDensityEstimation.boundary","page":"API","title":"KernelDensityEstimation.boundary","text":"B = boundary(spec)\n\nConvert the specification spec to a boundary style B.\n\nPackages may specialize this method on the spec argument to modify the behavior of the boundary inference for new argument types.\n\n\n\n\n\n","category":"function"},{"location":"api/#KernelDensityEstimation.bounds","page":"API","title":"KernelDensityEstimation.bounds","text":"lo, hi, boundary = bounds(data::AbstractVector{T}, spec) where {T}\n\nDetermine the appropriate interval, from lo to hi with boundary style boundary, for the density estimate, given the data vector data and KDE argument bounds.\n\nPackages may specialize this method on the spec argument to modify the behavior of the interval and boundary refinement for new argument types.\n\n\n\n\n\n","category":"function"},{"location":"api/#KernelDensityEstimation.estimate","page":"API","title":"KernelDensityEstimation.estimate","text":"estim, info = estimate(method::AbstractKDEMethod, data::AbstractVector; kwargs...)\nestim, info = estimate(method::AbstractKDEMethod, data::AbstractKDE, info::AbstractKDEInfo; kwargs...)\n\nApply the kernel density estimation algorithm method to the given data, either in the form of a vector of data or a prior density estimate and its corresponding pipeline info (to support being part of a processing pipeline).\n\nReturns\n\nestim::AbstractKDE: The resultant kernel density estimate.\ninfo::AbstractKDEInfo: Auxiliary information describing details of the density estimation either useful or necessary for constructing a pipeline of processing steps.\n\n\n\n\n\n","category":"function"},{"location":"api/#KernelDensityEstimation.estimator_order","page":"API","title":"KernelDensityEstimation.estimator_order","text":"p = estimator_order(::Type{<:AbstractKDEMethod})\n\nThe bias scaning of the density estimator method, where a return value of p corresponds to bandwidth-dependent biases of the order mathcalO(h^2p).\n\n\n\n\n\n","category":"function"},{"location":"showcase/#Showcase","page":"Showcase","title":"Showcase","text":"","category":"section"},{"location":"showcase/#[Simple-Distributions](showcase/distributions.md)","page":"Showcase","title":"Simple Distributions","text":"","category":"section"},{"location":"showcase/","page":"Showcase","title":"Showcase","text":"(Image: )","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"CurrentModule = KernelDensityEstimation","category":"page"},{"location":"userguide/#User-Guide","page":"User Guide","title":"User Guide","text":"","category":"section"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"Pages = [\"userguide.md\"]\nDepth = 2:2","category":"page"},{"location":"userguide/#Getting-Started","page":"User Guide","title":"Getting Started","text":"","category":"section"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"To install KernelDensityEstimation.jl, it is recommended that you use the jmert/Registry.jl package registry, which will let you install (and depend on) the package similarly to any other Julia package in the default General registry.","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"pkg> registry add https://github.com/jmert/Registry.jl\n\npkg> add KernelDensityEstimation","category":"page"},{"location":"userguide/#Simple-kernel-density-estimate","page":"User Guide","title":"Simple kernel density estimate","text":"","category":"section"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"using Distributions\nusing Markdown\nusing Random\nusing CairoMakie\nCairoMakie.activate!(type = \"svg\")\n\nRandom.seed!(101)","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"For the following example, we'll use a small sample of Gaussian deviates:","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"using KernelDensityEstimation\nx = 3 .+ 0.1 .* randn(250) # x ~ Normal(3, 0.1)\nnothing  # hide","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"The key interface of this package is the kde function. In its simplest incantation, you provide a vector of data and it returns a kernel density object (in the form of a UnivariateKDE structure).","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"using KernelDensityEstimation\n\nK = kde(x)\nnothing  # hide","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"The density estimate f(x) is given at locations K.x (as a StepRangeLen) with density values K.f. For instance, the mean and variance of the distribution are:","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"μ1 = step(K.x) * sum(@. K.f * K.x)\nμ2 = step(K.x) * sum(@. K.f * K.x^2)\n\n(; mean = μ1, std = sqrt(μ2 - μ1^2))","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"which agree well with the known underlying parameters (mu = 3 sigma = 01).","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"Visualizing the density estimate (see Extensions — Makie.jl), we see a fair level of consistency between the density estimate and the known underlying model.","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"fig = Figure(size = (400, 400))\nax = Axis(fig[1, 1])\n\nlines!(K.x, pdf.(Normal(3, 0.1), K.x), color = :blue3, linestyle = :dash, label = \"model\")\nlines!(K, color = :firebrick3, label = \"density estimate\")\nLegend(fig[2, 1], ax, orientation = :horizontal)\n\nsave(\"getting_started_1.svg\", fig)","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"(Image: )","category":"page"},{"location":"userguide/#Densities-with-boundaries","page":"User Guide","title":"Densities with boundaries","text":"","category":"section"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"The previous example arises often and is handled well by most kernel density estimation solutions. Being a Gaussian distribution makes it particularly well behaved, but in general distributions which are unbounded and gently fade away to zero towards pminfty are relatively easy to deal with. Despite how often the Gaussian distribution is an appropriate [approximation of the] distribution, there are still many cases where various bounded distributions are expected, and ignoring the boundary conditions can lead to a very poor density estimate.","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"Take the simple case of the uniform distribution on the interval 0 1.","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"Random.seed!(101)  # hide\nx = rand(5_000)\nnothing  # hide","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"By default, kde assumes the distribution is unbounded, and this leads to \"smearing\" the density across the known boundaries to the regions x  0 and x  1:","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"K0 = kde(x)\nnothing  # hide","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"fig = Figure(size = (400, 400))\nax = Axis(fig[1, 1])\n\nlines!(ax, [0, 0, 1, 1], [0, 1, 1, 0], color = :blue3, linestyle = :dash, label = \"uniform\")\nlines!(ax, K0, color = :firebrick3, label = \"density estimate\")\nLegend(fig[2, 1], ax, orientation = :horizontal)\n\nsave(\"getting_started_unbound_unif.svg\", fig)","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"(Image: )","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"We can inform the estimator that we expect a bounded distribution, and it will use that information to generate a more appropriate estimate. To do so, we make use of three keyword arguments in combination:","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"lo to dictate the lower bound of the data.\nhi to dictate the upper bound of the data.\nboundary to specify the boundary condition, such as :open (unbounded), :closed (finite), and half-open intervals :closedleft/:openright and :closedright/:openright.","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"In this example, we know our data is bounded on the closed interval 0 1, so we can improve the density estimate by providing that information","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"K1 = kde(x, lo = 0, hi = 1, boundary = :closed)\nnothing  # hide","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"fig = Figure(size = (400, 400))\nax = Axis(fig[1, 1])\n\nlines!(ax, K0, color = :grey75)\nlines!(ax, [0, 0, 1, 1], [0, 1, 1, 0], color = :blue3, linestyle = :dash, label = \"uniform\")\nlines!(ax, K1, color = :firebrick3, label = \"density estimate\")\nLegend(fig[2, 1], ax, orientation = :horizontal)\n\nsave(\"getting_started_limit_unif.svg\", fig)","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"(Image: )","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"Note that in addition to preventing the smearing of the density beyond the bounds of the known distribution, the density estimate with correct boundaries is also smoother than the unbounded estimate. This is because the sharp drops at x = 0 1 no longer need to be represented, so the algorithm is no longer compromising on smoothing the interior of the distribution with retaining the cut-offs.","category":"page"},{"location":"userguide/","page":"User Guide","title":"User Guide","text":"See the docstring for kde (and references therein) for more information on the behavior of the lo, hi, and boundary keyword arguments.","category":"page"},{"location":"explain/#Explanation","page":"Explanation","title":"Explanation","text":"","category":"section"},{"location":"explain/","page":"Explanation","title":"Explanation","text":"Pages = [\"explain.md\"]\nDepth = 2:2","category":"page"},{"location":"explain/#Estimator-Pipeline","page":"Explanation","title":"Estimator Pipeline","text":"","category":"section"},{"location":"explain/#Direct-Comparisons","page":"Explanation","title":"Direct Comparisons","text":"","category":"section"},{"location":"explain/","page":"Explanation","title":"Explanation","text":"The following figures provide direct comparisons of the four major steps in the estimator pipeline described above through their visual impact on a few example distributions.","category":"page"},{"location":"explain/","page":"Explanation","title":"Explanation","text":"LinearBinning: The data is histogrammed onto a uniformly spaced grid.\nFor visualization purposes, the histograms are plotted with bins with a width equal to the automatically determined bandwidth (see Bandwidth Estimators below) for the distribution, whereas the remaining panels use 8× as many data points to achieve a smoother curve.\nBasicKDE: This step convolves with the histogram with the Gaussian kernel in order to smooth the data from a discontinuous histogram into a smooth curve.\nThe basic density estimator is sufficient for an unbounded and smooth distribution like the Normal case. In the cases of the HalfNormal and Uniform distributions that have non-zero boundaries, though, the distribution is severely underestimated near the boundaries.\nLinearBoundaryKDE: This step corrects for the boundary effects by recovering both the normalization (due to convolving with implicit zeros beyond the boundary) and recovers the slope of the distribution near boundaries.\nCompared to the BasicKDE step, the HalfNormal and Uniform distributions near their boundaries are significantly improved.\nMultiplicativeBiasKDE: The final stage permits use of a larger bandwidth to achieve a smoother density estimate without sacrificing the sharpness of any curves / peaks. The algorithm automatically increases the bandwidth when the multiplicative bias correction is used.\nThe visual impact is more subtle than in previous stages, but the smoothness of the Uniform and Chisq3 distributions compared to the previous stage are a consequence of the multiplicative bias correction permitting a larger kernel bandwidth (without broadening the peak in the Chisq3 distribution).","category":"page"},{"location":"explain/","page":"Explanation","title":"Explanation","text":"details: Plotting Code\nusing CairoMakie\nusing Distributions\nusing Random\n\nimport KernelDensityEstimation as KDE\n\ndists = [\n    \"Normal\" => Normal(0.0, 1.0),\n    \"Chisq3\" => Chisq(3.0),\n    \"HalfNormal\" => truncated(Normal(0.0, 1.0); lower = 0.0),\n    \"Uniform\" => Uniform(0.0, 1.0),\n]\n\nestimators = [\n    KDE.LinearBinning(),\n    KDE.BasicKDE(),\n    KDE.LinearBoundaryKDE(),\n    KDE.MultiplicativeBiasKDE(),\n]\n\nfor (name, dist) in dists\n    fig = Figure(size = (900, 400))\n    axs = Axis[]\n\n    for (ii, method) in enumerate(estimators)\n        dohist = method isa KDE.AbstractBinningKDE\n\n        Random.seed!(123)  # hide\n        rv = rand(dist, 5_000)\n        dens = KDE.kde(rv; method, bounds = dist, bwratio = dohist ? 1 : 8)\n\n        ax = Axis(fig[1, ii]; title = string(nameof(typeof(method))),\n                              xlabel = \"value\", ylabel = \"density\")\n        lines!(ax, dist, color = (:black, 0.5), linestyle = :dash, label = \"true\")\n        plotter! = method isa KDE.AbstractBinningKDE ? stairs! : lines!\n        plotter!(ax, dens; label = \"estimate\",\n                           color = dohist ? :blue3 : :firebrick3)\n        scatter!(ax, [0], [0], color = (:black, 0.0))  # transparent dot to stop suppressed y=0 axis\n        ii > 1 && hideydecorations!(ax, grid = false, ticks = false)\n\n        push!(axs, ax)\n    end\n    linkaxes!(axs...)\n\n    Label(fig[0, :], name, font = :bold, fontsize = 20)\n    save(\"comparison_$name.svg\", fig)\nend\nnothing  # hide","category":"page"},{"location":"explain/","page":"Explanation","title":"Explanation","text":"(Image: ) (Image: ) (Image: ) (Image: )","category":"page"},{"location":"explain/#Bandwidth-Estimators","page":"Explanation","title":"Bandwidth Estimators","text":"","category":"section"},{"location":"showcase/distributions/#showcase_simple","page":"Simple distributions","title":"Simple distributions","text":"","category":"section"},{"location":"showcase/distributions/","page":"Simple distributions","title":"Simple distributions","text":"(Image: )","category":"page"},{"location":"showcase/distributions/#Source-Code","page":"Simple distributions","title":"Source Code","text":"","category":"section"},{"location":"showcase/distributions/","page":"Simple distributions","title":"Simple distributions","text":"import Markdown\nsourcecode = read(joinpath(dirname(@__FILE__), \"distributions.jl\"), String)\nMarkdown.parse(\"\"\"\n```julia\n$sourcecode\n```\n\"\"\")","category":"page"},{"location":"#Kernel-Density-Estimation","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"","category":"section"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"import Markdown\nreadmetxt = read(joinpath(dirname(@__FILE__), \"..\", \"..\", \"README.md\"), String)\nreadme = Markdown.parse(readmetxt)\n\n# Keep the contents between the title heading and the first horizontal rule (exclusive)\nii = findfirst(x -> x isa Markdown.Header{1}, readme.content)\njj = findfirst(x -> x isa Markdown.HorizontalRule, readme.content)\nreadme.content = readme.content[ii+1:jj-1]\n\nreadme","category":"page"},{"location":"#Why-another-kernel-density-estimation-package?","page":"Kernel Density Estimation","title":"Why another kernel density estimation package?","text":"","category":"section"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"As of Nov 2024, much of the Julia ecosystem uses the KernelDensity.jl package (possibly implicitly, such as through density plots in Makie.jl, StatsPlots.jl, etc).","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Consider the following (toy) examples: one case where we have samples drawn from a Gaussian distribution, and a second where only the positive values are retained.","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"using Random\nRandom.seed!(1234)  # hide\n\n# A vector of Gaussian random deviates\nrv_gauss = randn(500)\n# and its expected distribution\nx = -5.0:0.01:5.0\nexp_gauss = @. exp(-x^2 / 2) / sqrt(2π)\n\n# Then filter the random deviates to be strictly positive\nrv_trunc = filter(>(0.0), rv_gauss)\n# and its corresponding distribution (×2 to keep normalization)\nexp_trunc = @. ifelse(x > 0.0, 2exp_gauss, 0.0)\nnothing  # hide","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"details: Plotting Setup\nusing CairoMakie\n\nfunction draw_KD(grid, rv, (x, exp_dist), (z, kde_dist), title)\n    ax = Axis(grid, title = title)\n    # draw the reference expectation distribution\n    lines!(ax, x, exp_dist, linestyle = :dash, color = :black)\n    # draw the kernel density estimate\n    lines!(ax, z, kde_dist, linewidth = 2, color = Cycled(1))\n\n    # add a shadow axis and marks along the bottom edge to indicate\n    # the location of the random deviates\n    ax2 = Axis(grid, limits = (nothing, (0.0, 1.0)))\n    vlines!(ax2, rv, ymin=0.0, ymax=0.03, linewidth = 0.5, color = (:black, 0.2))\n    hidedecorations!(ax2)\n    hidespines!(ax2)\n    linkxaxes!(ax2, ax)\n\n    # fix the range of the axes\n    xlims!(ax2, -5.9, 5.9)\nend\nnothing  # hide","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"If we then plot the outputs of running the KernelDensity.kde method on each of these two vectors:","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"import KernelDensity as KD\n\nkd_gauss = KD.kde(rv_gauss)\nkd_trunc = KD.kde(rv_trunc)\nnothing  # hide","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"(Image: )","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"details: Plotting Code\nfig = Figure(size = (800, 400))\n\n# Gaussian distribution & KDE\nref = (x, exp_gauss)\nkd = (kd_gauss.x, kd_gauss.density)\ndraw_KD(fig[1, 1], rv_gauss, ref, kd, \"Gaussian\")\n\n# Truncation Gaussian distribution & KDE\nref = (x, exp_trunc)\nkd = (kd_trunc.x, kd_trunc.density)\ndraw_KD(fig[1, 2], rv_trunc, ref, kd, \"Truncated Gaussian\")\n\nLabel(fig[0, :], \"KernelDensity.jl\", font = :bold, fontsize = 20)\n\nsave(\"example_kerneldensity.svg\", fig)  # hide\nnothing  # hide","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"For the Gaussian distribution (left) where there are no edges, the density estimate appears to be a reasonable approximation of the known Gaussian distribution. In comparison, though, the truncated Gaussian distribution (right) fails to represent the hard cut-off at x = 0, instead \"leaking\" below zero with non-zero density despite the known closed boundary.","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Closed boundaries are common among many probability distributions,[bounded] and therefore the need to estimate a density corresponding to a (semi-)bounded distribution arises often. This package provides a density estimator that uses any provided boundary conditions to account for edge boundary effects, reproducing a more faithful representation of the underlying distribution.","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"[bounded]: For example, see the list of distributions with bounded and semi-infinite support on Wikipedia.","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Repeating the density estimation on the Gaussian and truncated Gaussian distributions shown above instead with this package's kde method:","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"import KernelDensityEstimation as KDE\n\nkde_gauss = KDE.kde(rv_gauss)\nkde_trunc = KDE.kde(rv_trunc, lo = 0.0, boundary = :closedleft)\nnothing  # hide","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"(Image: )","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"details: Plotting Code\nfig = Figure(size = (800, 400))\n\n# Gaussian distribution & KDE\nref = (x, exp_gauss)\nkd = (kde_gauss...,)\ndraw_KD(fig[1, 1], rv_gauss, ref, kd, \"Gaussian\")\n\n# Truncation Gaussian distribution & KDE\nref = (x, exp_trunc)\nkd = (kde_trunc...,)\ndraw_KD(fig[1, 2], rv_trunc, ref, kd, \"Truncated Gaussian\")\n\nLabel(fig[0, :], \"KernelDensityEstimation.jl\", font = :bold, fontsize = 20)\n\nsave(\"example_kerneldensityestimation.svg\", fig)  # hide\nnothing  # hide","category":"page"},{"location":"","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Most obviously, the truncated distribution retains its closed boundary condition at x = 0 and does not suffer from the leakage and suppression of the peak that occurs with the KernelDensity estimator. Furthermore, both density curves are smoother due to use of higher-order estimators which simultaneously permit using [relatively] wider bandwidth kernels while retaining the shapes of peaks (and non-flat slopes at closed boundaries).","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"CurrentModule = KernelDensityEstimation","category":"page"},{"location":"releasenotes/#Release-Notes","page":"Release Notes","title":"Release Notes","text":"","category":"section"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"Pages = [\"releasenotes.md\"]\nDepth = 2:2","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"","category":"page"},{"location":"releasenotes/#v0.6.0-—-2024-Dec-31","page":"Release Notes","title":"v0.6.0 — 2024 Dec 31","text":"","category":"section"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"Public functions have been declared using Julia v1.11+'s public keyword.\nThe value of the bin-center for the zero-width singleton histogram has been fixed.\nImplement more accurate histogram (and linear) binning calculations. For the HistogramBinning case, it is now possible to precisely bin range(lo, hi, nbins) values into their corresponding bins (whereas previously values may be counted incorrectly one bin too low due to rounding in the floating point calculations).\nThe implementation has been modified to support unitful quantities (without adding a new package dependency) via careful consideration and application of appropriate factors of one and/or oneunit (and relaxing type constraints or adding new type parameters to structs, where necessary). Given a vector with units u, the density object's fields (K.x, K.f) have units (u, u^-1), respectively, in correspondence with interpreting any integrated range to be a unitless probability (i.e. probability = sum(K.f[a .< K.x .< b]) * step(K.x)).\nThe package no longer depends on Roots.jl (used by the ISJ bandwidth estimator); instead, an implementation of Brent's Method is now included here directly. This not only decreases the dependence on external packages but also reduces both package load time and the precompiled package image size.\nThe documentation has generally been improved:\nA new \"Showcase\" section has been added to showcase examples of density estimation with this package.\nA User Guide has been started to give a brief introduction to installing and using the package.\nThe documentation now includes release notes.","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"","category":"page"},{"location":"releasenotes/#v0.5.0-—-2024-Nov-21","page":"Release Notes","title":"v0.5.0 — 2024 Nov 21","text":"","category":"section"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"Have the ISJ bandwidth estimator fallback to Silverman rule automatically when it fails to converge. This is expected to happen for very flat (closed) distributions, so it's not as rare of an occurrence as originally understood.\nAdd package extension to aid in plotting with Makie.jl.\nBegin adding more extensive documentation to the package:\nAdd a README to give brief justification for the package.\nDescribe the package extensions available and what features they provide.\nDemonstrate the impact of the different stages of the estimator pipeline by comparing each stage for several example distributions.","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"","category":"page"},{"location":"releasenotes/#v0.4.0-—-2024-Sep-09","page":"Release Notes","title":"v0.4.0 — 2024 Sep 09","text":"","category":"section"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"Add an interface method boundary which can be overloaded to implement mechanisms for automatically determining appropriate boundary conditions.\nThe two built-in methods are to convert from symbols to enum (e.g. :open to Open) and to infer the boundary conditions from a 2-tuple of finite/infinite real values.\nAdd an interface method bounds (and eponymous keyword argument to kde) which can be overloaded to implement mechanisms for automatically both the boundary condition (keyword boundary) and limits (keywords lo and hi) from an arbitrary value.\nStore more information within the UnivariateKDEInfo structure. The init uses the new fields to pass relevant parameters to later stages of the estimator pipeline.\nOn Julia v1.9+, new extension packages have been added to integrate with external packages:\nThe aforementioned boundary and bounds methods have been specialized for univariate distributions from Distributions.jl\nThe UnicodePlots.jl package, if loaded, is used to visualize the kernel density estimate at the terminal.\nIncrease the automatic bandwidth determined by the chosen bandwidth estimator for higher-order estimators (such as MultiplicativeBiasKDE) which have a lower level of bias. (See Lewis [2], §E, Eqn 35 and Footnote 10 for further details.)\nRename the boundary condition enum from Cover to Boundary.\nFix syntax or usage errors that broke compatibility with Julia v1.6.","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"A. Lewis. GetDist: a Python package for analysing Monte Carlo samples (2019), arXiv:1910.13970.","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"","category":"page"},{"location":"releasenotes/#v0.3.0-—-2024-Jul-21","page":"Release Notes","title":"v0.3.0 — 2024 Jul 21","text":"","category":"section"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"This release adds the ISJ bandwidth estimator described in Botev et al. [4] and uses it by default, as it is more capable of dealing both with non-Gaussian distributions and respects the complexity/nature of bounded domains.","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"Add an implementation of the Improved Sheather-Jones bandwidth estimator.\nRename the interface method for bandwidth estimators to bandwidth.\nConsolidate data and option pre-processing into the init method, which is the first step in the density estimation pipeline.","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"Z. Botev, J. Grotowski and D. Kroese. Kernel density estimation via diffusion.  The Annals of Statistics 38 (2010),  arXiv:1011.2602.","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"","category":"page"},{"location":"releasenotes/#v0.2.0-—-2024-Jul-19","page":"Release Notes","title":"v0.2.0 — 2024 Jul 19","text":"","category":"section"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"Require Julia v1.6+.\nImproved docstrings throughout.\nAdded framework for building documentation with Documenter.jl.\nMigrate specific density estimation implementations to be methods of the (new) estimate interface function (rather than overloading kde).\nFix handing of edge-case where a constant vector is given. For closed boundary conditions, the result is a zero-width singleton bin.\nFix error in widening of the KDE range based on the kernel bandwidth.","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"","category":"page"},{"location":"releasenotes/#v0.1.0-—-2024-Jul-13","page":"Release Notes","title":"v0.1.0 — 2024 Jul 13","text":"","category":"section"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"Initial release supports:","category":"page"},{"location":"releasenotes/","page":"Release Notes","title":"Release Notes","text":"Univariate kernel density estimation.\n2 binning methods (histogramming and linear binning) and 3 density estimation techniques (basic, with linear boundary correction, and/or with multiplicative bias correction\nSupport for distributions with (half-)closed boundary conditions.\nAutomatic bandwidth selection using Silverman's rule.","category":"page"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"CurrentModule = KernelDensityEstimation","category":"page"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"using CairoMakie\nupdate_theme!(size = (400, 300))","category":"page"},{"location":"extensions/#Package-Extensions","page":"Package Extensions","title":"Package Extensions","text":"","category":"section"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"Pages = [\"extensions.md\"]\nDepth = 2:2","category":"page"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"important: Important\nThis section describes features that are only available when using Julia v1.9 or newer.","category":"page"},{"location":"extensions/#ext-distributions","page":"Package Extensions","title":"Distributions.jl","text":"","category":"section"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"A univariate distribution from Distributions.jl can be used as a value for the bounds argument of kde, wherein the boundary conditions of the distribution will be used to automatically set appropriate values of lo, hi, and boundary.","category":"page"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"For example, generating a density estimate for a non-negative parameter in a Markov chain Monte Carlo (MCMC) chain is often paired with a similarly non-negative prior. Instead of needing to explicitly determine and pass through the correct combination of lower and upper bounds and their boundary conditions, the prior distribution can be used instead.","category":"page"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"using KernelDensityEstimation\nusing Distributions\nusing Random  # hide\nRandom.seed!(1234)  # hide\n\n# a non-negative constraint on a prior\nprior = truncated(Normal(0.0, 1.0), lower = 0.0)\n# proxy for an MCMC chain\nchain = rand(prior, 200)\n\n# prior-based boundary information on left is same as explicit options on right\nkde(chain; bounds = prior) == kde(chain; lo = 0.0, boundary = :closedleft)","category":"page"},{"location":"extensions/#ext-makie","page":"Package Extensions","title":"Makie.jl","text":"","category":"section"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"Plotting the UnivariateKDE object is natively supported within the Makie.jl system of packages. The density estimate is converted via the PointsBased trait and defaults to a line plot.","category":"page"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"Plotting via stairs is a special case, which correctly offsets the bin centers to the trailing bin edge (compatible with the default step = :pre behavior) and adds points to close the histogram with the x-axis.","category":"page"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"using KernelDensityEstimation: kde, LinearBinning\nusing Random  # hide\nRandom.seed!(100)  # hide\n\n# 500 samples from a Chisq(ν=4) distribution\nrv = dropdims(sum(abs2, randn(4, 500), dims=1), dims=1)\nnothing  # hide","category":"page"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"using CairoMakie\n\nK = kde(rv; lo = 0.0, boundary = :closedleft)\nH = kde(rv; lo = 0.0, boundary = :closedleft,\n            bwratio = 1.0, method = LinearBinning())\n\nfig = Figure(size=(800, 300))\nax1 = Axis(fig[1, 1], title=\"stairs\", ylabel = \"density\", xlabel = \"value\")\nax2 = Axis(fig[1, 2], title=\"lines\")\nlinkaxes!(ax1, ax2)\nhideydecorations!(ax2, grid = false, ticks = false)\n\nstairs!(ax1, H)\nlines!(ax2, K)\n\nsave(\"ext_makie.svg\", current_figure())  # hide\nnothing  # hide","category":"page"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"(Image: )","category":"page"},{"location":"extensions/#ext-unicodeplots","page":"Package Extensions","title":"UnicodePlots.jl","text":"","category":"section"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"For quick, approximate visualization of a density within the terminal, an extension is provided for the UnicodePlots.jl package. The three-argument Base.show method is defined to show the Unicode plot by default, so the distribution will be previewed at the REPL automatically.","category":"page"},{"location":"extensions/","page":"Package Extensions","title":"Package Extensions","text":"using KernelDensityEstimation\nusing UnicodePlots\nusing Random  # hide\nRandom.seed!(100)  # hide\n\n# 500 samples from a Chisq(ν=4) distribution\nrv = dropdims(sum(abs2, randn(4, 500), dims=1), dims=1)\nK = kde(rv; lo = 0.0, boundary = :closedleft)","category":"page"}]
}
